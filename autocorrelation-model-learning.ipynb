{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timesynth as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_sampler = ts.TimeSampler(stop_time=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irregular_time_samples = time_sampler.sample_irregular_time(num_points=500, keep_percentage=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irregular_time_samples_diff = np.diff(np.append(0, irregular_time_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi = 0.10\n",
    "sigma = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal = np.zeros(len(irregular_time_samples)+1)\n",
    "noise_samples = np.random.normal(size=len(irregular_time_samples))\n",
    "for i in range(len(irregular_time_samples)):\n",
    "    signal[i+1] = np.power(phi, irregular_time_samples_diff[i])*signal[i] + \\\n",
    "                    sigma*np.sqrt(1 - np.power(phi, 2*irregular_time_samples_diff[i]))*noise_samples[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(irregular_time_samples, signal[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for building the dictionary\n",
    "def create_data_dictionary(phi, sigma, irregular_time_samples, signal):\n",
    "    data_dict = {}\n",
    "    data_dict['phi'] = phi\n",
    "    data_dict['sigma'] = sigma\n",
    "    data_dict['time_samples'] = list(irregular_time_samples)\n",
    "    data_dict['signal'] = list(signal)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_file(file_name, data_dict):\n",
    "    with open('../corr_data/'+file_name+'.json', 'w') as fp:\n",
    "        json.dump(data_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open('../corr_data/'+file_name+'.json', 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(phi, sigma, num_points):\n",
    "    time_sampler = ts.TimeSampler(stop_time=20)\n",
    "    irregular_time_samples = time_sampler.sample_irregular_time(num_points=num_points,\n",
    "                                                                keep_percentage=50)\n",
    "    irregular_time_samples_diff = np.diff(np.append(0, irregular_time_samples))\n",
    "    signal = np.zeros(len(irregular_time_samples)+1)\n",
    "    noise_samples = np.random.normal(size=len(irregular_time_samples))\n",
    "    for i in range(len(irregular_time_samples)):\n",
    "        signal[i+1] = np.power(phi, irregular_time_samples_diff[i])*signal[i] + \\\n",
    "                        sigma*np.sqrt(1 - np.power(phi, 2*irregular_time_samples_diff[i]))*noise_samples[i]\n",
    "    return irregular_time_samples, signal[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating the process for dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "phi_samples = np.random.uniform(size=num_samples)\n",
    "sigma_samples = np.random.uniform(size=num_samples)\n",
    "signal_lengths = np.random.randint(low=500, high=1000, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    sigma = sigma_samples[i]\n",
    "    phi = phi_samples[i]\n",
    "    sig_length = signal_lengths[i]\n",
    "    signal = np.nan\n",
    "    while np.any(np.isnan(signal)):\n",
    "        time_samples, signal = generate_data(phi, sigma, 600)\n",
    "    data_dict = create_data_dictionary(phi, sigma, time_samples, signal)\n",
    "    file_name = 'series_'+str(i)\n",
    "    write_file(file_name, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the models for learning phi alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeflow as tflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMLayer():\n",
    "    \"\"\"\n",
    "    This layer implements the LSTM cell.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_layer_size, input_layer):\n",
    "        \"\"\"Initialize LSTMLayer class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : integer\n",
    "            Input dimensions\n",
    "        hidden_layer_size : integer\n",
    "            Size of the memory in LSTM cell\n",
    "        input_layer : layers object\n",
    "            Preceding layers object\n",
    "\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.inputs = input_layer.get_outputs()\n",
    "\n",
    "        # Initializing the weights and biases\n",
    "        self.Wi = tf.Variable(tf.zeros([self.input_dim, self.hidden_layer_size]))\n",
    "        self.Ui = tf.Variable(tf.zeros([self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        self.Wf = tf.Variable(tf.zeros([self.input_dim, self.hidden_layer_size]))\n",
    "        self.Uf = tf.Variable(tf.zeros([self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        self.Wog = tf.Variable(tf.zeros([self.input_dim, self.hidden_layer_size]))\n",
    "        self.Uog = tf.Variable(tf.zeros([self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        self.Wc = tf.Variable(tf.zeros([self.input_dim, self.hidden_layer_size]))\n",
    "        self.Uc = tf.Variable(tf.zeros([self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        self.initial_hidden = tf.zeros([1, self.hidden_layer_size])\n",
    "        self.initial_hidden= tf.pack([self.initial_hidden, self.initial_hidden])\n",
    "\n",
    "    def forward_step(self, previous_memory, input_):\n",
    "        \"\"\"\n",
    "        Generates the next forward LSTM operation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        previous_memory : list\n",
    "            List of the previous memory and hidden output tensors\n",
    "        input_ : tf.tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            New updated memory and hidden output tensors\n",
    "\n",
    "        \"\"\"\n",
    "        previous_hidden_state, c_prev = tf.unpack(previous_memory)\n",
    "        # Input gate\n",
    "        i= tf.sigmoid(\n",
    "            tf.matmul(input_,self.Wi)+tf.matmul(previous_hidden_state,self.Ui) + self.bi\n",
    "        )\n",
    "        # Forget Gate\n",
    "        f= tf.sigmoid(\n",
    "            tf.matmul(input_,self.Wf)+tf.matmul(previous_hidden_state,self.Uf) + self.bf\n",
    "        )\n",
    "        # Output Gate\n",
    "        o= tf.sigmoid(\n",
    "            tf.matmul(input_,self.Wog)+tf.matmul(previous_hidden_state,self.Uog) + self.bog\n",
    "        )\n",
    "        # New Memory Cell\n",
    "        c_= tf.nn.tanh(\n",
    "            tf.matmul(input_,self.Wc)+tf.matmul(previous_hidden_state,self.Uc) + self.bc\n",
    "        )\n",
    "        # Final Memory cell\n",
    "        c= f*c_prev + i*c_\n",
    "\n",
    "        # Current Hidden state\n",
    "        current_hidden_state = o*tf.nn.tanh(c)\n",
    "        return tf.pack([current_hidden_state,c])\n",
    "\n",
    "    # Function for getting all hidden state.\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        tf.Tensor\n",
    "            Output tensor\n",
    "\n",
    "        \"\"\"\n",
    "        # Getting all hidden state throuh time\n",
    "        inputs_shape = self.inputs.get_shape()\n",
    "        if inputs_shape[0] == 1:\n",
    "            self.inputs = tf.expand_dims(self.inputs[0, :, :], 1)\n",
    "            all_hidden_states = tf.scan(self.forward_step,\n",
    "                                        self.inputs,\n",
    "                                        initializer=self.initial_hidden,\n",
    "                                        name='states')\n",
    "            all_hidden_states = all_hidden_states[:, 0, :, :]\n",
    "        else:\n",
    "            all_hidden_states = tf.map_fn(self.get_batch_outputs,\n",
    "                                          self.inputs)\n",
    "        return all_hidden_states\n",
    "    \n",
    "    def get_batch_outputs(self, single_input):\n",
    "        single_input = tf.expand_dims(single_input, 1)\n",
    "        all_hidden_states = tf.scan(self.forward_step,\n",
    "                                    single_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name='states')\n",
    "        all_hidden_states = all_hidden_states[:, 0, :, :]\n",
    "        return all_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RegressionLayer():\n",
    "    \"\"\"\n",
    "    Layer implements the Simple regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, input_layer):\n",
    "            \"\"\"Initialize RegressionLayer class\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            input_size : integer\n",
    "                Input dimensions\n",
    "            output_size : integer\n",
    "                Output dimensions\n",
    "            input_layer : layers object\n",
    "                Preceding layers object\n",
    "\n",
    "            \"\"\"\n",
    "            self.inputs = input_layer.get_outputs()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            self.Wo = tf.Variable(tf.truncated_normal([self.input_size, self.output_size], mean=0, stddev=.01))\n",
    "            self.bo = tf.Variable(tf.truncated_normal([self.output_size], mean=0, stddev=.01))\n",
    "\n",
    "    def get_output(self, input_):\n",
    "        \"\"\"\n",
    "        Generates the output for a single step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ : tf.tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        tf.tensor\n",
    "            Output tensor\n",
    "\n",
    "        \"\"\"\n",
    "        output = tf.matmul(input_, self.Wo) + self.bo\n",
    "        return output\n",
    "\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterates through all inputs to generate outputs\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        tf.Tensor\n",
    "            Output tensor\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.inputs.get_shape()) == 3:\n",
    "            all_outputs = tf.map_fn(self.get_output, self.inputs)\n",
    "        else:\n",
    "            all_outputs = tf.map_fn(self.get_batch_outputs, self.inputs)\n",
    "        return all_outputs\n",
    "    \n",
    "    def get_batch_outputs(self, single_input):\n",
    "        all_single_outputs = tf.map_fn(self.get_output, single_input)\n",
    "        return all_single_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanLayer():\n",
    "    \"\"\"\n",
    "    Layer implements the Simple mean.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_layer):\n",
    "        \"\"\"Initialize MeanLayer class\n",
    "        \"\"\"\n",
    "        self.inputs = input_layer.get_outputs()\n",
    "\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Using all inputs to generate outputs\n",
    "        \"\"\"\n",
    "        output = tf.reduce_mean(self.inputs, reduction_indices=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 100 \n",
    "output_size = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Input'):\n",
    "    inputs = tflow.placeholders.prediction.input_batch_placeholder(input_size, batch_size)\n",
    "with tf.variable_scope('Input_LSTM_Layer'):\n",
    "    input_lstm_layer = tflow.layers.InputLSTMLayer(inputs, input_size, batch_input=True)\n",
    "with tf.variable_scope('LSTM_Layer'):\n",
    "    lstm_layer = LSTMLayer(input_size, hidden_size, input_lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Mean_Layer'):\n",
    "    mean_layer = MeanLayer(lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Reg_Layer'):\n",
    "    reg_layer = RegressionLayer(hidden_size, output_size, mean_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = reg_layer.get_outputs()[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[batch_size, output_size],name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('RMSE'):\n",
    "    rmse = tflow.utils.metrics.RMSE(outputs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.scalar_summary(\"RMSE\", rmse)\n",
    "summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training with Adadelta Optimizer\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.2).minimize(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Starting tensorflow session\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up log directory for tensorboard\n",
    "logs_path = 'tmp/corr/1'\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_batch_input(val, batch_size):\n",
    "    outputs = np.zeros(batch_size)\n",
    "    counter = 0\n",
    "    for k in range(val*batch_size, (val+1)*batch_size):\n",
    "        data_dict = read_file('series_'+str(k))\n",
    "        time_samples = data_dict['time_samples']\n",
    "        samples = data_dict['signal']\n",
    "        outputs[counter] = data_dict['phi']\n",
    "        if counter == 0:\n",
    "            input_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "        elif counter == 1:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.stack((input_vector, value_vector))\n",
    "        else:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.append(input_vector, np.expand_dims(value_vector, 0), axis=0)\n",
    "        counter += 1\n",
    "    return input_vector, np.reshape(outputs, (batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_random_batch_input(batch_size):\n",
    "    outputs = np.zeros(batch_size)\n",
    "    counter = 0\n",
    "    random_files = np.random.choice(10000, size=batch_size, replace=False)\n",
    "    for k in range(batch_size):\n",
    "        data_dict = read_file('series_'+str(random_files[k]))\n",
    "        time_samples = data_dict['time_samples']\n",
    "        samples = data_dict['signal']\n",
    "        outputs[counter] = data_dict['phi']\n",
    "        if counter == 0:\n",
    "            input_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "        elif counter == 1:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.stack((input_vector, value_vector))\n",
    "        else:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.append(input_vector, np.expand_dims(value_vector, 0), axis=0)\n",
    "        counter += 1\n",
    "    return input_vector, np.reshape(outputs, (batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(50):\n",
    "    input_vector, out_vector = build_random_batch_input(batch_size)\n",
    "    _, summary = sess.run([train_step, summary_op],\n",
    "                         feed_dict={inputs:input_vector,\n",
    "                                    y:out_vector})\n",
    "    writer.add_summary(summary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Batch \"+str(i+1)+\" Completed with RMSE: \"+str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = read_file('series_'+str(0))\n",
    "time_samples = data_dict['time_samples']\n",
    "samples = data_dict['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_batch_input(file_num, batch_size):\n",
    "    data_dict = read_file('series_'+str(file_num))\n",
    "    time_samples = data_dict['time_samples']\n",
    "    samples = data_dict['signal']\n",
    "    outputs = data_dict['phi']\n",
    "    for k in range(batch_size):\n",
    "        if k == 0:\n",
    "            input_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "        elif k == 1:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.stack((input_vector, value_vector))\n",
    "        else:\n",
    "            value_vector = np.transpose(np.concatenate(\n",
    "                                    (np.array(time_samples, ndmin=2),\n",
    "                                     np.array(samples, ndmin=2)), axis=0))\n",
    "            input_vector = np.append(input_vector, np.expand_dims(value_vector, 0), axis=0)\n",
    "    return input_vector, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_test, value = build_batch_input(1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = sess.run(outputs, feed_dict={inputs:in_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
